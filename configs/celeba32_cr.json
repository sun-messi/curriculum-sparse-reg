// Mode CR: Curriculum + Regularization (RegUNet with Group L1 on bottleneck-adjacent layers) - 32x32
//
// Usage:
//   Single GPU:
//     python train_curriculum.py --config-path configs/celeba32_cr.json
//
//   Multi-GPU (6 GPUs):
//     python train_curriculum.py --config-path configs/celeba32_cr.json --num-gpus 6 --distributed --rigid-launch
//
// 9-Stage Lambda Schedule (gradual decay):
//   High noise [0.2, 1.0]: Strong regularization with gradual decrease
//   Mid noise [0.07, 0.2]: Progressive relaxation
//   Low noise [0.0, 0.07]: Rapid decay to zero
//
//   Stage | t_min | lambda   | epochs | 说明
//   ------|-------|----------|--------|------
//     0   |  0.3  | 0.001200 |   1    | 强正则 (20x increase)
//     1   |  0.2  | 0.001000 |   1    | 缓降
//     2   | 0.15  | 0.000800 |   1    | 逐步放松
//     3   |  0.1  | 0.000600 |   1    |
//     4   | 0.07  | 0.000400 |   2    |
//     5   | 0.05  | 0.000200 |   2    | 快速下降
//     6   | 0.03  | 0.000100 |   2    |
//     7   | 0.01  | 0.000040 |   2    |
//     8   |  0.0  | 0.000000 |   4    | 无正则
//
// Loss Formula: L_total = MSE_loss + λ × Σ_c ||W[c,:,:,:]||_2
//   where layers = {downsamples.level_3[1].conv1, downsamples.level_3[1].conv2} (last ResBlock before bottleneck)
//
{
  "dataset": "celeba32",
  "diffusion": {
    "timesteps": 1000,
    "beta_start": 0.0001,
    "beta_end": 0.02,
    "beta_schedule": "linear",
    "model_mean_type": "eps",
    "model_var_type": "fixed-small",
    "loss_type": "mse"
  },
  "model": {
    "in_channels": 3,
    "hid_channels": 128,
    "ch_multipliers": [1, 2, 2, 2],
    "num_res_blocks": 2,
    "apply_attn": [false, false, true, false],
    "drop_rate": 0.0
  },
  "train": {
    "lr": 2e-4,
    "batch_size": 128,
    "grad_norm": 1.0,
    "epochs": 100,
    "warmup": 5000,
    "use_ema": true,
    "ema_decay": 0.9999,
    "num_samples": 24,
    "image_intv": 1,
    "chkpt_intv": 1
  },
  "curriculum": {
    "enabled": true,
    "stages": [
      {"t_min": 0.3,  "t_max": 1.0, "epochs": 1, "lambda": 0.0012,  "name": "stage0_coarse"},
      {"t_min": 0.2,  "t_max": 1.0, "epochs": 1, "lambda": 0.0008,   "name": "stage1_coarse"},
      {"t_min": 0.15, "t_max": 1.0, "epochs": 1, "lambda": 0.00005,  "name": "stage2_detail"},
      {"t_min": 0.1,  "t_max": 1.0, "epochs": 1, "lambda": 0.00003,  "name": "stage3_detail"},
      {"t_min": 0.07, "t_max": 1.0, "epochs": 2, "lambda": 0.00001,  "name": "stage4_fine"},
      {"t_min": 0.05, "t_max": 1.0, "epochs": 2, "lambda": 0.000,  "name": "stage5_fine"},
      {"t_min": 0.03, "t_max": 1.0, "epochs": 2, "lambda": 0.000,  "name": "stage6_finer"},
      {"t_min": 0.01, "t_max": 1.0, "epochs": 2, "lambda": 0.000, "name": "stage7_finer"},
      {"t_min": 0.0,  "t_max": 1.0, "epochs": 4, "lambda": 0.0,     "name": "stage8_finest"}
    ]
  },
  "sparsity": {
    "enabled": false,
    "initial_sparsity": 0.8,
    "regrowth_method": "gradient"
  },
  "regularization": {
    "enabled": true,
    "lambda_max": 0.0012
  }
}
